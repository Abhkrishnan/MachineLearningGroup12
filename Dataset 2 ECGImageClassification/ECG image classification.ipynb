{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a4e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c843863-da8a-415e-b5db-c5222204e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk(os.getcwd()):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6873c2-1715-429d-a9d2-bee53a2f4b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'ECG_DATA/train'\n",
    "test_dir = 'ECG_DATA/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d48cc-5e91-41d8-9e49-d66974035705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subfolders_and_image_counts(directory):\n",
    "    subfolders = {}\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        if dirs:\n",
    "            for folder in dirs:\n",
    "                folder_path = os.path.join(subdir, folder)\n",
    "                num_images = len([file for file in os.listdir(folder_path) if file.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "                subfolders[folder] = num_images\n",
    "    return subfolders\n",
    "\n",
    "train_subfolders = get_subfolders_and_image_counts(train_dir)\n",
    "test_subfolders = get_subfolders_and_image_counts(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fcf0a9-daa4-45b4-97de-67c06858edba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Subfolders and Image Counts:\")\n",
    "for folder, count in train_subfolders.items():\n",
    "    print(f\"{folder}: {count} images\")\n",
    "\n",
    "print(\"\\nTest Subfolders and Image Counts:\")\n",
    "for folder, count in test_subfolders.items():\n",
    "    print(f\"{folder}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efc9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation using Image Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ca079",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2  \n",
    "    ,rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    "\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb86ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataGenerator(train_dir,test_dir):\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(224, 224),  \n",
    "        batch_size=34,\n",
    "        class_mode='categorical',color_mode='grayscale', # Clss_mode = 'categorical 'simplifies that its one hot encoded\n",
    "        subset='training'  \n",
    "    )\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',color_mode='grayscale',\n",
    "        subset='validation'  \n",
    "    )\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(224, 224),color_mode='grayscale',\n",
    "        batch_size=32,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    return train_generator,validation_generator, test_generator\n",
    "# print(\"Class indices:\", train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGenerated, validationGenerated, testGenerated = dataGenerator(train_dir,test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134af9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class indices:\", trainGenerated.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbcefc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs(history): \n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('ModelAccuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f4225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlpModelFun():\n",
    "    mlpModel = models.Sequential([\n",
    "        layers.Flatten(input_shape=(224,224,1)),\n",
    "\n",
    "\n",
    "        layers.Dense(256,activation='relu'),\n",
    "        layers.Dropout(0.1),\n",
    "\n",
    "        layers.Dense(128,activation='relu'),\n",
    "        layers.Dropout(0.1),\n",
    "\n",
    "        layers.Dense(64,activation='relu'),\n",
    "        layers.Dropout(0.1),\n",
    "\n",
    "        layers.Dense(len(trainGenerated.class_indices))\n",
    "    ])\n",
    "\n",
    "    mlpModel.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    trainGenerated = trainGenerated.repeat()  # Add this line to repeat the training data\n",
    "    validationGenerated = validationGenerated.repeat()\n",
    "    \n",
    "    history = mlpModel.fit(\n",
    "    trainGenerated,\n",
    "    steps_per_epoch=trainGenerated.samples // trainGenerated.batch_size,\n",
    "    validation_data=validationGenerated,\n",
    "    validation_steps=validationGenerated.samples // validationGenerated.batch_size,\n",
    "    epochs=25  \n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f51f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class indices:\", trainGenerated.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a6901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs(mlpModelHistory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
